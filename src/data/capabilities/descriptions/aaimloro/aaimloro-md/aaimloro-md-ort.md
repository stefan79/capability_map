## Capability Overview
Analytical AI encompasses the application of machine learning (ML) and operations research (OR) techniques to analyze data, identify patterns, and generate actionable insights. This capability addresses the need for data-driven decision-making by enabling predictive, prescriptive, and diagnostic analytics across enterprise functions. It supports complex problem-solving where traditional rule-based systems are insufficient, facilitating optimization and forecasting in dynamic environments. Analytical AI is foundational for transforming raw data into measurable business value without prescribing specific implementation technologies.

## Business Value & Supported Use Cases
- Enables improved decision accuracy and speed through predictive modeling and optimization.
- Supports use cases such as demand forecasting, fraud detection, customer segmentation, supply chain optimization, and risk assessment.
- Facilitates operational efficiency by automating data analysis and scenario evaluation.
- Relevant across AI adoption stages:
  - Experimentation: validating analytical models on pilot datasets.
  - Scale-out: expanding models across business units.
  - Industrialization: embedding analytics into core business processes.
  - Regulated production: ensuring compliance and auditability of analytical outputs.

## Maturity Expectations
- Emerging: Basic ML models or optimization algorithms applied in isolated projects with limited integration or governance.
- Well-established: Standardized analytical workflows with repeatable model development, validation, and deployment processes.
- Strategic / Differentiating: Advanced analytics integrated with enterprise data platforms, enabling real-time decision support and continuous model improvement.
- Foundational: Analytical AI is embedded in enterprise architecture with robust governance, scalability, and cross-functional adoption.
- “Good” at scale means consistent model performance, traceability, and alignment with business objectives.
- Under-maturity signs include ad hoc analytics, lack of model monitoring, poor data quality, and limited stakeholder engagement.

## Mandatory vs Optional Usage
- Mandatory when:
  - Analytical AI supports production-critical decisions impacting revenue, compliance, or operational risk.
  - Deployed at enterprise scale requiring standardized processes and governance.
  - Operating within regulated environments demanding audit trails and explainability.
- Optional when:
  - Used for exploratory analysis or proof-of-concept projects with limited scope.
  - Applied in isolated teams without direct impact on core business processes.
- The classification ensures appropriate investment in controls and scalability proportional to business impact.

## Key Dependencies & Related Capabilities
- Technical:
  - Data management and integration capabilities providing clean, accessible data.
  - Model development environments and feature engineering tools.
- Governance:
  - AI model risk management frameworks ensuring compliance and ethical use.
  - Data privacy and security policies.
- Operational:
  - MLOps pipelines for model deployment, monitoring, and lifecycle management.
  - Change management processes for model updates.
- Related capabilities:
  - Generative AI for augmenting analytical insights.
  - Platform Operations & MLOps / LLMOps for operationalizing models.
  - Governance, Risk & Compliance for oversight and control.

## Risks of Omission or Poor Implementation
- Architectural risks include siloed analytics leading to inconsistent insights and duplicated efforts.
- Operational risks involve model degradation, lack of monitoring, and inability to respond to changing data patterns.
- Compliance risks arise from insufficient documentation, lack of explainability, and failure to meet regulatory requirements.
- Common failure modes include overfitting, data bias, and poor integration with business workflows resulting in low adoption.

## Example Metrics & KPIs
- Model accuracy, precision, recall, or other relevant performance indicators.
- Percentage of analytical models deployed to production versus in development.
- Time-to-insight from data ingestion to actionable output.
- Number of models monitored with automated alerts for performance drift.
- Compliance audit pass rates related to model governance.
- User adoption rates and satisfaction scores for analytical tools.
