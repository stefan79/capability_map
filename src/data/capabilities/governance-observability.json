{
  "id": "go",
  "title": "Governance & Observability",
  "children": [
    {
      "id": "agg",
      "title": "AI Governance & Guardrails",
      "children": [
        {
          "id": "raf",
          "title": "Responsible AI Framework",
          "status": "not implemented",
          "type": "policy",
          "description": "A Responsible AI framework provides a set of principles, guidelines, and best practices for developing and deploying AI systems in an ethical and trustworthy manner. It addresses fairness, accountability, transparency, and the societal impact of AI.",
          "link": "https://www.ibm.com/think/topics/responsible-ai"
        },
        {
          "id": "pd",
          "title": "PII detection",
          "status": "not implemented",
          "type": "technology",
          "description": "Personally Identifiable Information (PII) detection is the process of identifying and protecting sensitive data within text and other data sources. This is a critical component of data privacy and compliance in AI applications.",
          "link": "https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/overview"
        },
        {
          "id": "dmc",
          "title": "Data & Model cards",
          "status": "not implemented",
          "type": "policy",
          "description": "Data and model cards are documents that provide standardized information about datasets and machine learning models. They increase transparency by detailing the performance characteristics, intended use cases, and ethical considerations.",
          "link": "https://modelcards.withgoogle.com/"
        },
        {
          "id": "hav",
          "title": "Human-assisted Verification",
          "status": "partially",
          "type": "pattern",
          "description": "Human-assisted verification combines AI-powered automation with human expertise to validate and review AI-driven decisions. This 'human-in-the-loop' approach is crucial for high-stakes applications where accuracy and accountability are paramount.",
          "link": "https://www.veriff.com"
        },
        {
          "id": "cm",
          "title": "Content Moderation",
          "status": "not implemented",
          "type": "policy",
          "description": "AI-powered content moderation uses machine learning to automatically detect and filter inappropriate or harmful content from online platforms. It helps maintain a safe and positive user environment by identifying text, images, and videos that violate community guidelines.",
          "link": "https://getstream.io/blog/ai-content-moderation/"
        },
        {
          "id": "gth",
          "title": "Guardrails (toxic, hallucinations...)",
          "status": "not implemented",
          "type": "policy",
          "description": "AI guardrails are safety measures designed to prevent large language models (LLMs) from generating harmful, toxic, or fabricated content (hallucinations). They enforce rules and constraints to ensure that model outputs are accurate, appropriate, and aligned with safety standards.",
          "link": "https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails"
        },
        {
          "id": "bdm",
          "title": "Bias Detection & Mitigation",
          "status": "not implemented",
          "type": "pattern",
          "description": "Bias detection and mitigation techniques are used to identify and reduce unfair or discriminatory outcomes in AI systems. These methods help ensure that models are equitable and do not perpetuate societal biases present in the training data.",
          "link": "https://www.sap.com/resources/what-is-ai-bias"
        }
      ]
    },
    {
      "id": "co",
      "title": "Common Operations",
      "children": [
        {
          "id": "f",
          "title": "FinOps",
          "status": "not implemented",
          "type": "policy",
          "description": "FinOps is a cultural practice that brings financial accountability to the variable spend model of cloud and AI, enabling organizations to get maximum business value. It involves collaboration between finance, technology, and business teams to manage costs effectively.",
          "link": "https://www.finops.org/wg/finops-for-ai-overview/"
        },
        {
          "id": "cf",
          "title": "Collect Feedback",
          "status": "not implemented",
          "type": "pattern",
          "description": "Collecting user feedback is the process of gathering input from users about the performance and outputs of an AI model. This feedback is essential for identifying issues and providing data for continuous model improvement.",
          "link": "https://towardsdatascience.com/user-feedback-the-missing-piece-of-your-ml-monitoring-stack-46b2bbf0b5e4"
        }
      ]
    }
  ]
}
