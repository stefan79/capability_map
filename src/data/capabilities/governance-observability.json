{
  "id": "go",
  "title": "Governance & Observability",
  "productId": "genai-hub",
  "children": [
    {
      "id": "go-agg",
      "title": "AI Governance & Guardrails",
      "children": [
        {
          "id": "go-agg-raf",
          "title": "Responsible AI Framework",
          "reviewed": "false",
          "type": "policy",
          "description": "Policies and controls for safety, fairness, transparency, and accountability. Principles and processes to ensure AI is developed and used ethically with accountability and transparency. Establishes governance across the AI lifecycle and compliance with regulations.",
          "link": "https://oecd.ai/en/ai-principles",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-pii",
          "title": "PII detection",
          "reviewed": "false",
          "type": "technology",
          "description": "Identify/redact sensitive data across inputs/outputs/logs. Automated identification of personally identifiable information in text and data to support privacy and compliance. Used to redact or protect sensitive data before model use.",
          "link": "https://learn.microsoft.com/azure/ai-services/language-service/personally-identifiable-information/overview",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-dmc",
          "title": "Data, Model & Agent cards",
          "reviewed": "false",
          "type": "policy",
          "description": "Standard fact sheets with purpose, risks, metrics, and owners. Standardized documentation describing datasets, models, and agents: purpose, performance, risks, and limitations. Improves transparency and responsible adoption.",
          "link": "https://modelcards.withgoogle.com/",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-hitl",
          "title": "Human in the Loop Escalation",
          "reviewed": "false",
          "status": 1,
          "type": "pattern",
          "description": "Route uncertain or flagged outputs to human reviewers. Operational pattern to route uncertain or high\u2011risk AI decisions to human reviewers. Ensures oversight and auditability for critical interactions.",
          "link": "https://arxiv.org/abs/2002.01024",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-owm",
          "title": "Open Weights models",
          "reviewed": "false",
          "type": "policy",
          "description": "Curated OSS models with license and security checks. Guidelines for approving and managing models with open weights, including security and IP considerations. Balances innovation with risk management.",
          "link": "https://crfm.stanford.edu/2023/05/10/open-foundation-models.html",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-wuic",
          "title": "Whitelisted UI Channels",
          "reviewed": "false",
          "type": "policy",
          "description": "Approved apps/surfaces for AI use. Restrict end\u2011user access to approved applications and interfaces for AI interactions. Reduces data leakage and shadow AI risks.",
          "link": "https://www.ncsc.gov.uk/collection/caf/caf-principles/governance",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-agg-cm",
          "title": "Content Moderation",
          "reviewed": "false",
          "type": "policy",
          "description": "Safety filters for harmful/illegal content. Policies and automated checks to detect abuse, toxicity, and policy violations in AI inputs and outputs. Protects users and brand safety.",
          "link": "https://platform.openai.com/docs/guides/safety-best-practices",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            }
          },
          "useCaseRefs": [
            {
              "hviaId": "sales-acceleration",
              "useCaseId": "sales-acceleration-default",
              "maturity": 0
            },
            {
              "hviaId": "warranty-cost-reduction",
              "useCaseId": "warranty-cost-reduction-default",
              "maturity": 0
            },
            {
              "hviaId": "new-ai-services",
              "useCaseId": "new-ai-services-default",
              "maturity": 0
            },
            {
              "hviaId": "e2e-sop",
              "useCaseId": "e2e-sop-default",
              "maturity": 0
            },
            {
              "hviaId": "dev-productivity",
              "useCaseId": "dev-productivity-default",
              "maturity": 0
            },
            {
              "hviaId": "white-collar-productivity",
              "useCaseId": "white-collar-productivity-default",
              "maturity": 2
            },
            {
              "hviaId": "mack",
              "useCaseId": "mack-mavis",
              "maturity": 2
            }
          ]
        },
        {
          "id": "go-agg-gr",
          "title": "Guardrails (toxic, hallucinations\u2026)",
          "reviewed": "false",
          "type": "policy",
          "description": "Pre/post-processing to constrain generation and reduce risk. Safety controls such as validation, filters, and constrained generation to prevent harmful or fabricated outputs. Enforces organizational and legal standards.",
          "link": "https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          },
          "useCaseRefs": [
            {
              "hviaId": "sales-acceleration",
              "useCaseId": "sales-acceleration-default",
              "maturity": 0
            },
            {
              "hviaId": "warranty-cost-reduction",
              "useCaseId": "warranty-cost-reduction-default",
              "maturity": 0
            },
            {
              "hviaId": "new-ai-services",
              "useCaseId": "new-ai-services-default",
              "maturity": 0
            },
            {
              "hviaId": "e2e-sop",
              "useCaseId": "e2e-sop-default",
              "maturity": 0
            },
            {
              "hviaId": "dev-productivity",
              "useCaseId": "dev-productivity-default",
              "maturity": 0
            },
            {
              "hviaId": "white-collar-productivity",
              "useCaseId": "white-collar-productivity-default",
              "maturity": 2
            },
            {
              "hviaId": "mack",
              "useCaseId": "mack-mavis",
              "maturity": 2
            }
          ]
        },
        {
          "id": "go-agg-bdm",
          "title": "Bias Detection & Mitigation",
          "reviewed": "false",
          "status": 0,
          "type": "pattern",
          "description": "Metrics and interventions to reduce disparate impact. Techniques to measure and reduce unfair model behavior across groups and contexts. Improves equity and compliance with non\u2011discrimination rules.",
          "link": "https://developers.google.com/machine-learning/fairness-overview"
        }
      ]
    },
    {
      "id": "go-co",
      "title": "Common Operations",
      "children": [
        {
          "id": "go-co-finops",
          "title": "FinOps",
          "reviewed": "false",
          "type": "policy",
          "description": "Cost tracking/optimization for infra/GPU/LLM usage. Financial governance for variable AI and cloud spend to maximize value. Enables shared accountability across engineering, finance, and product.",
          "link": "https://www.finops.org/framework/",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        },
        {
          "id": "go-co-feedback",
          "title": "Collect Feedback",
          "reviewed": "false",
          "type": "pattern",
          "description": "Capture user ratings and corrections in workflows. Mechanisms to capture user and annotator feedback on model outputs for continuous improvement. Feeds evaluation and retraining loops.",
          "link": "https://evidentlyai.com/blog/ai-feedback-loops",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            }
          },
          "useCaseRefs": [
            {
              "hviaId": "sales-acceleration",
              "useCaseId": "sales-acceleration-default",
              "maturity": 0
            },
            {
              "hviaId": "warranty-cost-reduction",
              "useCaseId": "warranty-cost-reduction-default",
              "maturity": 0
            },
            {
              "hviaId": "new-ai-services",
              "useCaseId": "new-ai-services-default",
              "maturity": 0
            },
            {
              "hviaId": "e2e-sop",
              "useCaseId": "e2e-sop-default",
              "maturity": 1
            },
            {
              "hviaId": "dev-productivity",
              "useCaseId": "dev-productivity-default",
              "maturity": 0
            },
            {
              "hviaId": "white-collar-productivity",
              "useCaseId": "white-collar-productivity-default",
              "maturity": 2
            },
            {
              "hviaId": "mack",
              "useCaseId": "mack-mavis",
              "maturity": 1
            }
          ]
        },
        {
          "id": "go-co-sdg",
          "title": "Synthetic Data Generation",
          "reviewed": "false",
          "type": "technology",
          "description": "Tools to augment data with privacy protection. Tools and processes to generate privacy\u2011preserving synthetic datasets for development and testing. Helps overcome data scarcity and privacy limits.",
          "link": "https://www.nist.gov/itl/ai-risk-management-framework/synthetic-data",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 2,
              "reason": "Initial Suggestion from Stijn."
            }
          },
          "useCaseRefs": [
            {
              "hviaId": "sales-acceleration",
              "useCaseId": "sales-acceleration-default",
              "maturity": 0
            },
            {
              "hviaId": "warranty-cost-reduction",
              "useCaseId": "warranty-cost-reduction-default",
              "maturity": 0
            },
            {
              "hviaId": "new-ai-services",
              "useCaseId": "new-ai-services-default",
              "maturity": 0
            },
            {
              "hviaId": "e2e-sop",
              "useCaseId": "e2e-sop-default",
              "maturity": 0
            },
            {
              "hviaId": "dev-productivity",
              "useCaseId": "dev-productivity-default",
              "maturity": 0
            },
            {
              "hviaId": "white-collar-productivity",
              "useCaseId": "white-collar-productivity-default",
              "maturity": 2
            }
          ]
        },
        {
          "id": "go-co-edge",
          "title": "Edge AI",
          "reviewed": "false",
          "type": "technology",
          "description": "Deploy models to devices/vehicles with offline support. Deploy and monitor AI workloads on edge devices with constrained compute and intermittent connectivity. Requires specialized observability and update strategies.",
          "link": "https://azure.microsoft.com/solutions/edge-computing/what-is-edge-ai",
          "maturityInputs": {
            "technology.adoption-effort": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "technology.development-activity": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            },
            "process.documentation": {
              "value": 1,
              "reason": "Initial Suggestion from Stijn."
            }
          }
        }
      ]
    }
  ]
}