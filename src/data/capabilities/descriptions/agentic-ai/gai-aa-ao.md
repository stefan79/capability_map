## Capability Overview
The capability {{Capability}} within the {{Domain}} domain addresses the need to {{briefly describe the core problem or challenge this capability solves}}. It enables enterprises to {{describe the primary functional outcome or transformation enabled}} by providing structured approaches to {{general description of the problem space}}. This capability is essential for organizations aiming to {{describe the broader objective or operational improvement}} while maintaining alignment with enterprise standards and requirements.

## Business Value & Supported Use Cases
- Enables improved {{specific business outcome, e.g., decision-making, automation, insight generation}} through {{general method or approach}}.
- Supports use cases such as {{list 2–3 typical enterprise scenarios relevant to the capability}}.
- Relevant across AI adoption stages including:
  - Experimentation: Facilitates initial validation and prototyping.
  - Scale-out: Supports broader deployment across multiple teams or units.
  - Industrialization: Ensures robustness and repeatability in production environments.
  - Regulated production: Meets compliance and governance requirements for critical workloads.

## Maturity Expectations
- Emerging: Capability is in early adoption with limited integration, often manual or siloed, and lacks standardized processes.
- Well-established: Processes and tools are standardized, integrated with enterprise systems, and support repeatable outcomes.
- Strategic / Differentiating: Capability is optimized for competitive advantage, with automation, advanced analytics, and continuous improvement embedded.
- Foundational: Considered a core enterprise function, fully integrated, scalable, and compliant with governance frameworks.

At scale, “good” means consistent, reliable performance with clear metrics, seamless integration, and minimal manual intervention. Under-maturity is indicated by inconsistent results, lack of governance, and poor alignment with enterprise objectives.

## Mandatory vs Optional Usage
- Mandatory when:
  - Operating in regulated environments requiring auditability and compliance.
  - Deployed at enterprise scale where consistency and reliability are critical.
  - Supporting production-critical AI workloads with high availability and risk mitigation needs.
- Optional when:
  - Limited to proof-of-concept projects or isolated teams exploring new approaches.
  - Applied to non-critical or exploratory use cases where risk and impact are low.

Mandatory usage ensures risk is managed and outcomes are reliable, while optional usage allows flexibility during early experimentation or limited scope projects.

## Key Dependencies & Related Capabilities
- Technical:
  - Requires foundational data infrastructure and integration layers.
  - Depends on secure and scalable compute resources.
- Governance:
  - Relies on established AI governance frameworks and policies.
  - Needs compliance monitoring and risk management processes.
- Operational:
  - Depends on mature MLOps/LLMOps pipelines for deployment and monitoring.
  - Interfaces with platform operations for lifecycle management.

Downstream, this capability enables enhanced AI model performance, operational automation, and improved decision support. Related capabilities include data management, model governance, and platform operations.

## Risks of Omission or Poor Implementation
- Architectural risks include fragmented systems, inconsistent data usage, and scalability bottlenecks.
- Operational risks involve unreliable outputs, increased manual intervention, and slow response to issues.
- Compliance risks encompass audit failures, regulatory breaches, and lack of traceability.
- Common failure modes include siloed implementations, lack of standardization, and insufficient monitoring.

## Example Metrics & KPIs
- Adoption rate across business units or teams.
- Accuracy, precision, or other quality indicators relevant to the capability’s output.
- Compliance adherence rate and audit pass frequency.
- Mean time to detect and resolve operational issues.
- Cost per deployment or per use case.
- User satisfaction or stakeholder feedback scores.
